# ğŸ¯ TFG: PredicciÃ³n de Stock con Machine Learning

## ğŸ“Š Resultados Principales

### ğŸ† Mejores Algoritmos
- **ClasificaciÃ³n:** LightGBM - 81.8% accuracy
- **RegresiÃ³n:** Random Forest - RÂ² = 0.130

### ğŸ“ˆ Dataset
- **Total registros:** 4,530
- **Necesitan reposiciÃ³n:** 3,270 (72.2%)
- **Alias Ãºnicos:** 121
- **Tiendas Ãºnicas:** 2361

## ğŸ” ClasificaciÃ³n (Â¿Necesita reposiciÃ³n?)

| Algoritmo | CV Score | Test Accuracy |
|-----------|----------|---------------|
| LightGBM | 0.820 | **0.818** |
| XGBoost | 0.810 | **0.814** |
| Random Forest | 0.790 | **0.798** |
| KNN | 0.756 | **0.767** |
| SVM | 0.752 | **0.744** |
| Logistic Regression | 0.734 | **0.726** |

## ğŸ“Š RegresiÃ³n (Â¿CuÃ¡nto stock?)

| Algoritmo | MAE | RMSE | RÂ² |
|-----------|-----|------|-----|
| Random Forest | 1783.7 | 13625.3 | **0.130** |
| XGBoost | 1897.2 | 13644.7 | **0.127** |
| LightGBM | 2193.5 | 13856.5 | **0.100** |
| Linear Regression | 1873.6 | 13901.1 | **0.094** |
| Ridge | 1873.6 | 13901.2 | **0.094** |
| SVR | 1979.7 | 14694.2 | **-0.012** |

## ğŸ¯ Conclusiones Clave

- âœ… **Gradient Boosting domina:** XGBoost y LightGBM superan mÃ©todos tradicionales
- âœ… **ClasificaciÃ³n exitosa:** 81.8% accuracy vs RÂ² = 0.130 en regresiÃ³n  
- âœ… **Dataset balanceado:** 72.2% casos positivos
- âš ï¸ **RegresiÃ³n compleja:** PredicciÃ³n exacta de cantidad es desafiante
- ğŸ”§ **Features clave:** stock_ratio, STOCK_RECUENTOS, gap_to_max

## ğŸš€ ImplementaciÃ³n Recomendada

1. **Usar LightGBM** para clasificaciÃ³n en producciÃ³n
2. **Modelo hÃ­brido:** ClasificaciÃ³n + regresiÃ³n condicional
3. **Monitoreo continuo** de performance en producciÃ³n
4. **Incorporar features temporales** para mejorar predicciÃ³n

---
*Reporte generado automÃ¡ticamente - 22/06/2025*
