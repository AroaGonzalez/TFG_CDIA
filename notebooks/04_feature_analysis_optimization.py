# 04_feature_analysis_optimization.py
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import warnings
import json
from datetime import datetime
warnings.filterwarnings('ignore')

def load_data_and_results():
   """Cargar datos procesados y resultados de modelos anteriores"""
   try:
       df = pd.read_csv('data/processed/features_engineered.csv')
       
       with open('data/processed/feature_metadata.json', 'r') as f:
           metadata = json.load(f)
           features = metadata.get('features', [])
       
       class_results = pd.read_csv('results/classification_results.csv', index_col=0)
       reg_results = pd.read_csv('results/regression_results.csv', index_col=0)
       
       print(f"‚úÖ Datos cargados: {df.shape[0]} registros, {len(features)} features")
       print(f"‚úÖ Resultados anteriores: {len(class_results)} modelos de clasificaci√≥n, {len(reg_results)} modelos de regresi√≥n")
       
       return df, features, class_results, reg_results
   
   except FileNotFoundError as e:
       print(f"‚ùå Error: {e}")
       print("   Ejecuta primero los scripts anteriores (01, 02 y 03)")
       return None, None, None, None

def analyze_feature_importance():
   """Analizar importancia de caracter√≠sticas seg√∫n modelos anteriores"""
   print("\nüîç ANALIZANDO IMPORTANCIA DE CARACTER√çSTICAS")
   print("-" * 50)
   
   importance_files = [f for f in os.listdir('results') if f.startswith('importance_') and f.endswith('.csv')]
   
   if not importance_files:
       print("‚ùå No se encontraron an√°lisis de importancia. Ejecuta primero 03_model_comparison.py")
       return None
   
   all_importances = []
   
   for file in importance_files:
       model_name = file.replace('importance_', '').replace('.csv', '')
       imp_df = pd.read_csv(f'results/{file}')
       imp_df['model'] = model_name
       all_importances.append(imp_df)
   
   combined_imp = pd.concat(all_importances)
   
   avg_imp = combined_imp.groupby('feature')['importance'].mean().reset_index()
   avg_imp = avg_imp.sort_values('importance', ascending=False)
   
   plt.figure(figsize=(12, 8))
   top_n = min(20, len(avg_imp))
   sns.barplot(x='importance', y='feature', data=avg_imp.head(top_n))
   plt.title(f'Top {top_n} Caracter√≠sticas por Importancia Promedio')
   plt.tight_layout()
   plt.savefig('results/plots/feature_importance_aggregated.png', dpi=300)
   
   print(f"‚úÖ Top 10 caracter√≠sticas m√°s importantes:")
   for i, (_, row) in enumerate(avg_imp.head(10).iterrows(), 1):
       print(f"   {i}. {row['feature']}: {row['importance']:.4f}")
   
   return avg_imp

def select_optimal_features(df, features, importance_df, threshold=0.7):
   """Seleccionar caracter√≠sticas √≥ptimas basado en importancia acumulada"""
   print("\nüîé SELECCIONANDO CARACTER√çSTICAS √ìPTIMAS")
   print("-" * 50)
   
   if importance_df is None:
       print("‚ùå No se puede realizar selecci√≥n sin datos de importancia")
       return features
   
   total_imp = importance_df['importance'].sum()
   importance_df['importance_normalized'] = importance_df['importance'] / total_imp
   importance_df['importance_cumulative'] = importance_df['importance_normalized'].cumsum()
   
   selected_features = importance_df[importance_df['importance_cumulative'] <= threshold]['feature'].tolist()
   
   if len(selected_features) < 10:
       selected_features = importance_df.head(10)['feature'].tolist()
   
   print(f"‚úÖ Caracter√≠sticas seleccionadas: {len(selected_features)} de {len(features)}")
   print(f"   Umbral de importancia acumulada: {threshold:.1%}")
   
   valid_features = [f for f in selected_features if f in df.columns]
   if len(valid_features) < len(selected_features):
       print(f"‚ö†Ô∏è {len(selected_features) - len(valid_features)} caracter√≠sticas no est√°n disponibles en el dataframe")
   
   return valid_features

def prepare_optimized_datasets(df, selected_features):
   """Preparar conjuntos de datos optimizados para entrenamiento"""
   print("\nüìä PREPARANDO DATASETS OPTIMIZADOS")
   print("-" * 50)
   
   X = df[selected_features].copy()
   
   numeric_cols = X.select_dtypes(include=['number']).columns.tolist()
   if len(numeric_cols) < len(X.columns):
       print(f"‚ö†Ô∏è Se omitir√°n {len(X.columns) - len(numeric_cols)} columnas no num√©ricas")
       X = X[numeric_cols]
   
   for col in X.columns:
       if X[col].isna().sum() > 0:
           X[col] = X[col].fillna(X[col].median())
   
   y_class = df['necesita_reposicion'] if 'necesita_reposicion' in df.columns else None
   y_reg = df['cantidad_a_reponer'] if 'cantidad_a_reponer' in df.columns else None
   y_reg_log = df['log_cantidad_a_reponer'] if 'log_cantidad_a_reponer' in df.columns else None
   
   df_temp = pd.DataFrame({'fecha': df['FECHA_HORA_EJECUCION_STOCK_RECUENTOS'], 'X_index': X.index})
   fecha_corte = df_temp['fecha'].quantile(0.8)
   train_mask = df_temp['fecha'] <= fecha_corte
   test_mask = df_temp['fecha'] > fecha_corte
   
   X_train = X.loc[df_temp[train_mask]['X_index']]
   X_test = X.loc[df_temp[test_mask]['X_index']]
   y_class_train = y_class.loc[df_temp[train_mask]['X_index']]
   y_class_test = y_class.loc[df_temp[test_mask]['X_index']]
   
   mask_train = y_reg[X_train.index] > 0
   mask_test = y_reg[X_test.index] > 0
   
   X_reg_train = X_train[mask_train]
   y_reg_train = y_reg[X_train.index][mask_train]
   y_reg_log_train = y_reg_log[X_train.index][mask_train]
   
   X_reg_test = X_test[mask_test]
   y_reg_test = y_reg[X_test.index][mask_test]
   y_reg_log_test = y_reg_log[X_test.index][mask_test]
   
   # Crear segmentos para modelos espec√≠ficos por magnitud
   quantiles = [0, 0.25, 0.5, 0.75, 1.0]
   labels = ['Q1', 'Q2', 'Q3', 'Q4']
   
   y_reg_train_quantile = pd.qcut(y_reg_train, q=quantiles, labels=labels)
   segment_datasets = {}
   
   for segment in labels:
       mask_segment = y_reg_train_quantile == segment
       segment_datasets[segment] = {
           'X_train': X_reg_train[mask_segment],
           'y_train': y_reg_train[mask_segment],
           'y_train_log': y_reg_log_train[mask_segment]
       }
   
   print(f"‚úÖ Dataset de clasificaci√≥n: {X_train.shape[0]} train, {X_test.shape[0]} test")
   print(f"‚úÖ Dataset de regresi√≥n: {X_reg_train.shape[0]} train, {X_reg_test.shape[0]} test (solo casos > 0)")
   print(f"‚úÖ Datasets por segmentos creados: {', '.join([f'{k}: {v['X_train'].shape[0]} muestras' for k, v in segment_datasets.items()])}")
   
   return {
       'classification': (X_train, X_test, y_class_train, y_class_test),
       'regression': (X_reg_train, X_reg_test, y_reg_train, y_reg_test),
       'regression_log': (X_reg_train, X_reg_test, y_reg_log_train, y_reg_log_test),
       'segments': segment_datasets,
       'test_data': (X_reg_test, y_reg_test, y_reg_log_test)
   }

def optimize_classification_model(datasets):
   """Optimizar el modelo de clasificaci√≥n con SMOTE para balancear clases"""
   print("\nüîÑ OPTIMIZANDO MODELO DE CLASIFICACI√ìN")
   print("-" * 50)
   
   X_train, X_test, y_train, y_test = datasets['classification']
   
   # Crear pipeline con SMOTE para balancear clases
   pipeline = ImbPipeline([
       ('scaler', RobustScaler()),
       ('smote', SMOTE(random_state=42)),
       ('model', RandomForestClassifier(random_state=42, n_jobs=-1, verbose=0))
   ])
   
   param_grid = {
       'model__n_estimators': [100, 200, 300],
       'model__max_depth': [5, 10, 15],
       'model__min_samples_leaf': [2, 5, 10],
       'model__min_samples_split': [2, 5, 10],
       'model__class_weight': [None, 'balanced', 'balanced_subsample']
   }
   
   print("üîç Iniciando b√∫squeda de hiperpar√°metros para clasificaci√≥n...")
   grid_search = RandomizedSearchCV(
       pipeline, param_grid, cv=5, scoring='f1',
       n_iter=15, random_state=42, n_jobs=-1, verbose=0
   )
   
   grid_search.fit(X_train, y_train)
   
   best_model = grid_search.best_estimator_
   y_pred = best_model.predict(X_test)
   f1 = f1_score(y_test, y_pred)
   
   print(f"‚úÖ Mejores par√°metros: {grid_search.best_params_}")
   print(f"‚úÖ F1-Score: {f1:.4f}")
   print(f"‚úÖ El modelo usa SMOTE para balancear las clases")
   
   from joblib import dump
   os.makedirs('models', exist_ok=True)
   dump(best_model, 'models/optimized_classification_model.joblib')
   
   return best_model, grid_search.best_params_, f1

def train_segmented_regression_models(datasets):
   """Entrenar modelos de regresi√≥n por segmentos"""
   print("\nüìä ENTRENANDO MODELOS DE REGRESI√ìN POR SEGMENTOS")
   print("-" * 50)
   
   segments = datasets['segments']
   X_test, y_test, y_test_log = datasets['test_data']
   
   segment_models = {}
   segment_metrics = {}
   
   for segment_name, segment_data in segments.items():
       X_train = segment_data['X_train']
       y_train_log = segment_data['y_train_log']
       
       print(f"\nüîç Entrenando modelo para segmento {segment_name} ({len(X_train)} muestras)")
       
       # Pipeline con escalado y modelo
       pipeline = Pipeline([
           ('scaler', RobustScaler()),
           ('model', xgb.XGBRegressor(random_state=42, n_jobs=-1))
       ])
       
       # Usar par√°metros m√°s espec√≠ficos seg√∫n el segmento
       if segment_name in ['Q1', 'Q2']:  # Valores peque√±os
           params = {
               'model__n_estimators': 200,
               'model__max_depth': 3,
               'model__learning_rate': 0.01,
               'model__min_child_weight': 3,
               'model__gamma': 0.1,
               'model__subsample': 0.9,
               'model__colsample_bytree': 0.8
           }
       else:  # Valores grandes (Q3, Q4)
           params = {
               'model__n_estimators': 300,
               'model__max_depth': 5,
               'model__learning_rate': 0.05,
               'model__min_child_weight': 5,
               'model__gamma': 0.2,
               'model__subsample': 1.0,
               'model__colsample_bytree': 0.9
           }
       
       # Ajustar pipeline
       for param, value in params.items():
           pipeline.set_params(**{param: value})
       
       pipeline.fit(X_train, y_train_log)
       segment_models[segment_name] = pipeline
       
       # Guardar modelo
       from joblib import dump
       os.makedirs('models/segments', exist_ok=True)
       dump(pipeline, f'models/segments/regression_model_{segment_name}.joblib')
       
       print(f"‚úÖ Modelo para segmento {segment_name} entrenado y guardado")
   
   # Evaluar modelos combinados en test set
   print("\nüìä Evaluando modelos por segmentos en conjunto de prueba")
   
   # Crear predicciones combinadas
   # Para ello, necesitamos asignar cada muestra de test al segmento correspondiente
   y_pred_combined = np.zeros_like(y_test)
   
   # Determinar cuartiles basados en el conjunto de entrenamiento
   y_reg_train = np.concatenate([segments[s]['y_train'] for s in segments])
   quantile_values = np.percentile(y_reg_train, [25, 50, 75])
   
   # Asignar cada muestra de test a un segmento y predecir
   for i, y_val in enumerate(y_test):
       if y_val <= quantile_values[0]:
           segment = 'Q1'
       elif y_val <= quantile_values[1]:
           segment = 'Q2'
       elif y_val <= quantile_values[2]:
           segment = 'Q3'
       else:
           segment = 'Q4'
       
       # Predecir con el modelo del segmento correspondiente
       X_sample = X_test.iloc[[i]]
       y_pred_log = segment_models[segment].predict(X_sample)
       y_pred_combined[i] = np.expm1(y_pred_log[0])
   
   # Calcular m√©tricas
   mae = mean_absolute_error(y_test, y_pred_combined)
   rmse = np.sqrt(mean_squared_error(y_test, y_pred_combined))
   r2 = r2_score(y_test, y_pred_combined)
   
   print(f"‚úÖ MAE combinado: {mae:.2f}")
   print(f"‚úÖ RMSE combinado: {rmse:.2f}")
   print(f"‚úÖ R¬≤ combinado: {r2:.4f}")
   
   # Guardar m√©tricas
   segment_metrics = {
       'combined_metrics': {
           'mae': float(mae),
           'rmse': float(rmse),
           'r2': float(r2)
       },
       'segments': {s: {'samples': len(segment_data['X_train'])} for s, segment_data in segments.items()},
       'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
   }
   
   with open('models/segmented_regression_meta.json', 'w') as f:
       json.dump(segment_metrics, f, indent=2)
   
   return segment_models, segment_metrics

def evaluate_model(model, X_test, y_test_log):
    """Eval√∫a modelo de regresi√≥n con transformaci√≥n logar√≠tmica de forma consistente"""
    # Predecir en escala logar√≠tmica
    y_pred_log = model.predict(X_test)
    
    # Convertir a escala original para m√©tricas
    y_pred = np.expm1(y_pred_log)
    y_true = np.expm1(y_test_log)
    
    # Calcular m√©tricas
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    
    return mae, rmse, r2, y_pred

def optimize_regression_model(datasets):
   """Optimizar el modelo de regresi√≥n mediante GridSearch"""
   print("\nüìà OPTIMIZANDO MODELO DE REGRESI√ìN GLOBAL")
   print("-" * 50)
   
   # Usar datos con transformaci√≥n logar√≠tmica
   X_train, X_test, y_train, y_test = datasets['regression_log']
   
   # Probar tambi√©n transformaci√≥n ra√≠z cuadrada
   X_train_sqrt, X_test_sqrt, y_train_sqrt, y_test_sqrt = datasets['regression']
   y_train_sqrt = np.sqrt(y_train_sqrt)  # Transformaci√≥n ra√≠z cuadrada
   
   # Pipeline con escalado y modelo
   pipeline = Pipeline([
       ('scaler', RobustScaler()),
       ('model', xgb.XGBRegressor(random_state=42, n_jobs=-1))
   ])
   
   # Par√°metros para b√∫squeda
   param_grid = {
       'model__n_estimators': [200, 300, 500],
       'model__max_depth': [3, 5, 7],
       'model__learning_rate': [0.01, 0.05, 0.1],
       'model__min_child_weight': [1, 3, 5],
       'model__gamma': [0, 0.1, 0.2],
       'model__subsample': [0.8, 0.9, 1.0],
       'model__colsample_bytree': [0.8, 0.9, 1.0]
   }
   
   # Realizar b√∫squeda
   print("üîç Iniciando b√∫squeda de hiperpar√°metros para regresi√≥n...")
   grid_search = RandomizedSearchCV(
       pipeline, param_grid, cv=5, scoring='neg_mean_absolute_error',
       n_iter=20, random_state=42, n_jobs=-1, verbose=0
   )
   
   # Probar con transformaci√≥n logar√≠tmica (mejor en an√°lisis previo)
   grid_search.fit(X_train, y_train)
   
   # Evaluar modelo optimizado
   best_model = grid_search.best_estimator_
   y_pred_log = best_model.predict(X_test)
   
   # Transformar predicciones a escala original
   y_pred = np.expm1(y_pred_log)
   y_true = np.expm1(y_test)
   
   # Calcular m√©tricas
   mae = mean_absolute_error(y_true, y_pred)
   rmse = np.sqrt(mean_squared_error(y_true, y_pred))
   r2 = r2_score(y_true, y_pred)
   
   print(f"‚úÖ Mejores par√°metros: {grid_search.best_params_}")
   print(f"‚úÖ MAE: {mae:.2f}, RMSE: {rmse:.2f}, R¬≤: {r2:.4f}")
   
   # Guardar modelo optimizado
   from joblib import dump
   os.makedirs('models', exist_ok=True)
   dump(best_model, 'models/optimized_regression_model.joblib')
   
   # Guardar datos de referencia para transformaci√≥n
   model_meta = {
       'best_params': grid_search.best_params_,
       'metrics': {
           'mae': float(mae),
           'rmse': float(rmse),
           'r2': float(r2)
       },
       'transformation': 'logarithmic',
       'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
   }
   
   with open('models/optimized_regression_meta.json', 'w') as f:
       json.dump(model_meta, f, indent=2)
   
   return best_model, grid_search.best_params_, (mae, rmse, r2)

def analyze_errors(model, datasets, model_type='regression'):
   """Analizar errores del modelo optimizado"""
   print(f"\nüî¨ AN√ÅLISIS DE ERRORES - {model_type.upper()}")
   print("-" * 50)
   
   if model_type == 'regression':
       X_train, X_test, y_train, y_test = datasets['regression_log']
       
       # Hacer predicciones
       y_pred_log = model.predict(X_test)
       
       # Transformar a escala original
       y_pred = np.expm1(y_pred_log)
       y_true = np.expm1(y_test)
       
       # Calcular errores
       errors = y_true - y_pred
       abs_errors = np.abs(errors)
       
       # An√°lisis de errores
       error_df = pd.DataFrame({
           'y_true': y_true,
           'y_pred': y_pred,
           'error': errors,
           'abs_error': abs_errors
       })
       
       # Visualizar errores
       plt.figure(figsize=(10, 8))
       plt.subplot(2, 1, 1)
       plt.scatter(y_true, y_pred, alpha=0.5)
       plt.plot([0, y_true.max()], [0, y_true.max()], 'r--')
       plt.xlabel('Valor Real')
       plt.ylabel('Predicci√≥n')
       plt.title('Predicci√≥n vs Valor Real')
       
       plt.subplot(2, 1, 2)
       plt.scatter(y_true, abs_errors, alpha=0.5)
       plt.xlabel('Valor Real')
       plt.ylabel('Error Absoluto')
       plt.title('Error Absoluto vs Valor Real')
       
       plt.tight_layout()
       plt.savefig('results/plots/regression_error_analysis.png', dpi=300)
       
       # An√°lisis por segmentos
       quantiles = [0, 0.25, 0.5, 0.75, 1.0]
       labels = ['Q1', 'Q2', 'Q3', 'Q4']
       
       error_df['quantile'] = pd.qcut(y_true, q=quantiles, labels=labels)
       segment_analysis = error_df.groupby('quantile').agg({
           'y_true': 'mean',
           'abs_error': ['mean', 'median', 'std'],
           'error': ['mean', 'count']
       })
       
       print("\nüìä An√°lisis de errores por segmento:")
       print(segment_analysis.round(2))
       
       # Guardar an√°lisis
       segment_analysis.to_csv('results/regression_error_segments.csv')
       
   else:  # clasificaci√≥n
       X_train, X_test, y_train, y_test = datasets['classification']
       
       # Hacer predicciones
       y_pred = model.predict(X_test)
       
       # Matriz de confusi√≥n
       from sklearn.metrics import confusion_matrix, classification_report
       
       cm = confusion_matrix(y_test, y_pred)
       
       # Visualizar matriz de confusi√≥n
       plt.figure(figsize=(8, 6))
       sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['No Reponer', 'Reponer'],
                   yticklabels=['No Reponer', 'Reponer'])
       plt.xlabel('Predicci√≥n')
       plt.ylabel('Valor Real')
       plt.title('Matriz de Confusi√≥n')
       plt.tight_layout()
       plt.savefig('results/plots/classification_confusion_matrix.png', dpi=300)
       
       # Informe de clasificaci√≥n
       report = classification_report(y_test, y_pred, output_dict=True)
       report_df = pd.DataFrame(report).transpose()
       
       print("\nüìä Informe de clasificaci√≥n:")
       print(report_df.round(3))
       
       # Guardar informe
       report_df.to_csv('results/classification_report.csv')

def implement_hybrid_approach(datasets, class_model, reg_models=None):
   """Implementar enfoque h√≠brido: clasificar primero, luego predecir cantidad"""
   print("\nüîÑ IMPLEMENTANDO ENFOQUE H√çBRIDO")
   print("-" * 50)
   
   # Datos de prueba
   X_test, y_test = datasets['classification'][1], datasets['classification'][3]
   
   # Modelo de regresi√≥n global
   if reg_models is None:
       from joblib import load
       try:
           reg_model = load('models/optimized_regression_model.joblib')
       except:
           print("‚ö†Ô∏è No se encontr√≥ un modelo de regresi√≥n optimizado")
           return
   else:
       reg_model = reg_models  # Usar modelos por segmentos

   # Hacer predicciones de clasificaci√≥n
   y_class_pred = class_model.predict(X_test)
   
   # Encontrar √≠ndices donde se predice reposici√≥n
   indices_reposicion = np.where(y_class_pred == 1)[0]
   
   # Predecir cantidades solo para esos √≠ndices
   X_reposicion = X_test.iloc[indices_reposicion]
   
   # Convertir √≠ndices a posiciones en el conjunto de regresi√≥n
   X_reg_test = datasets['regression'][1]
   y_reg_test = datasets['regression'][2]
   
   # Mapear √≠ndices de clasificaci√≥n a √≠ndices de regresi√≥n
   # Esto es complejo porque no hay correspondencia directa entre ambos datasets
   # Asumimos que usamos predicci√≥n de modelo global para simplificar
   y_hybrid_pred = np.zeros_like(y_test, dtype=float)
   
   if isinstance(reg_model, dict):  # Modelos por segmentos
       # Implementaci√≥n con modelos por segmentos (m√°s compleja)
       print("‚úÖ Usando modelos por segmentos para enfoque h√≠brido")
       
       # Determinamos el segmento de cada muestra positiva
       y_reg_train = np.concatenate([datasets['segments'][s]['y_train'] for s in datasets['segments']])
       quantile_values = np.percentile(y_reg_train, [25, 50, 75])
       
       for idx in indices_reposicion:
           X_sample = X_test.iloc[[idx]]
           
           # Seleccionar modelo seg√∫n cantidad esperada (aproximaci√≥n)
           segment = 'Q2'  # Valor por defecto (mediano)
           
           # Hacer predicci√≥n con el modelo del segmento
           y_pred_log = reg_models[segment].predict(X_sample)
           y_hybrid_pred[idx] = np.expm1(y_pred_log[0])
   else:
       # Implementaci√≥n con modelo global
       print("‚úÖ Usando modelo global para enfoque h√≠brido")
       
       # Hacer predicciones para casos de reposici√≥n
       y_pred_log = reg_model.predict(X_reposicion)
       
       # Asignar predicciones
       for i, idx in enumerate(indices_reposicion):
           y_hybrid_pred[idx] = np.expm1(y_pred_log[i])
   
   # Calcular m√©tricas (solo para casos donde se predice reposici√≥n)
   y_true_reposicion = y_test.iloc[indices_reposicion]
   y_pred_reposicion = y_hybrid_pred[indices_reposicion]
   
   # M√©tricas de clasificaci√≥n
   from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
   accuracy = accuracy_score(y_test, y_class_pred)
   precision = precision_score(y_test, y_class_pred)
   recall = recall_score(y_test, y_class_pred)
   f1 = f1_score(y_test, y_class_pred)
   
   # M√©tricas h√≠bridas
   mae_hybrid = mean_absolute_error(y_true_reposicion, y_pred_reposicion)
   
   print(f"‚úÖ M√©tricas de clasificaci√≥n:")
   print(f"   ‚Ä¢ Accuracy: {accuracy:.4f}")
   print(f"   ‚Ä¢ Precision: {precision:.4f}")
   print(f"   ‚Ä¢ Recall: {recall:.4f}")
   print(f"   ‚Ä¢ F1-Score: {f1:.4f}")
   
   print(f"\n‚úÖ M√©tricas de regresi√≥n (solo para casos con reposici√≥n):")
   print(f"   ‚Ä¢ MAE: {mae_hybrid:.2f}")
   
   # Guardar metadatos del enfoque h√≠brido
   hybrid_meta = {
       'classification_metrics': {
           'accuracy': float(accuracy),
           'precision': float(precision),
           'recall': float(recall),
           'f1': float(f1)
       },
       'regression_metrics': {
           'mae': float(mae_hybrid)
       },
       'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
   }
   
   with open('models/hybrid_approach_meta.json', 'w') as f:
       json.dump(hybrid_meta, f, indent=2)
   
   return hybrid_meta

def main():
   print("üöÄ AN√ÅLISIS Y OPTIMIZACI√ìN DE CARACTER√çSTICAS")
   print("="*60)
   
   # Cargar datos y resultados
   df, features, class_results, reg_results = load_data_and_results()
   if df is None:
       return
   
   # Analizar importancia de caracter√≠sticas
   importance_df = analyze_feature_importance()
   
   # Seleccionar caracter√≠sticas √≥ptimas
   selected_features = select_optimal_features(df, features, importance_df, threshold=0.8)
   
   # Preparar datasets optimizados
   datasets = prepare_optimized_datasets(df, selected_features)
   
   # Optimizar modelo de clasificaci√≥n con SMOTE
   best_class_model, best_class_params, class_f1 = optimize_classification_model(datasets)
   
   # Optimizar modelo de regresi√≥n global
   best_reg_model, best_reg_params, reg_metrics = optimize_regression_model(datasets)
   
   # Entrenar modelos por segmentos
   segment_models, segment_metrics = train_segmented_regression_models(datasets)
   
   # Analizar errores
   analyze_errors(best_reg_model, datasets, model_type='regression')
   analyze_errors(best_class_model, datasets, model_type='classification')
   
   # Implementar enfoque h√≠brido
   hybrid_meta = implement_hybrid_approach(datasets, best_class_model, segment_models)
   
   # Guardar feature set optimizado
   feature_meta = {
       'selected_features': selected_features,
       'feature_count': len(selected_features),
       'optimization_threshold': 0.8,
       'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
   }
   
   with open('data/processed/optimized_features.json', 'w') as f:
       json.dump(feature_meta, f, indent=2)
   
   print("\n‚úÖ OPTIMIZACI√ìN COMPLETADA")
   print(f"üìÅ Archivos generados:")
   print(f"   ‚Ä¢ models/optimized_classification_model.joblib")
   print(f"   ‚Ä¢ models/optimized_regression_model.joblib")
   print(f"   ‚Ä¢ models/segments/ (modelos por segmentos)")
   print(f"   ‚Ä¢ data/processed/optimized_features.json")
   print(f"   ‚Ä¢ models/hybrid_approach_meta.json")
   print(f"   ‚Ä¢ results/plots/feature_importance_aggregated.png")
   print(f"   ‚Ä¢ results/plots/regression_error_analysis.png")
   print(f"   ‚Ä¢ results/plots/classification_confusion_matrix.png")
   
   # Resumen de resultados y recomendaciones
   print("\nüìã RESUMEN DE MEJORAS IMPLEMENTADAS:")
   print("1. ‚úÖ Clasificaci√≥n: Implementaci√≥n de SMOTE para balanceo de clases")
   print("2. ‚úÖ Regresi√≥n: Modelos espec√≠ficos por segmentos de magnitud")
   print("3. ‚úÖ Enfoque h√≠brido: Clasificaci√≥n seguida de regresi√≥n selectiva")
   
   return best_class_model, segment_models, selected_features

if __name__ == "__main__":
   best_class_model, segment_models, selected_features = main()